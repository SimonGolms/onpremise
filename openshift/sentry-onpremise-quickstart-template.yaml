apiVersion: v1
kind: Template
labels:
  app: "sentry"
  part-of: "sentry-on-premise"
  template: "sentry-on-premise-quickstart"
metadata:
  name: "sentry-on-premise-quickstart"
  annotations:
    description: >-
      Sentry is a realtime event logging and aggregation platform.
      It specializes in monitoring errors and extracting all the information needed to do a proper post-mortem without any of the hassle of the standard user feedback loop.
    iconClass: "fa fa-bug"
    openshift.io/display-name: "Sentry On-Premise (Quickstart)"
    openshift.io/documentation-url: "https://github.com/SimonGolms/sentry-onpremise-openshift"
    tags: "sentry,monitoring,error,bugs,quickstart"
parameters:
  - name: HTTP_PROXY
    displayName: http proxy
    description: http proxy for downloading configs
    value: ""
  - name: HTTPS_PROXY
    displayName: https proxy
    description: https proxy for downloading configs
    value: ""
  - name: NO_PROXY
    displayName: no proxy urls
    description: no proxy urls for downloading configs
    value: ""
  - name: SENTRY_SECRET_KEY
    displayName: Sentry Secret Key
    description: A secret string used to configure sentry. Changing this value will result in all current sessions being invalidated.
    generate: expression
    from: "[a-zA-Z0-9]{50}"
    required: true
  - name: SENTRY_HOST
    displayName: Sentry Hostname
    description: "A unique public application URL of Sentry (Route/host). The hostname can't be changed after the route is created."
    value: sentry.example.com
    required: true
  - name: ADMIN_USERNAME
    displayName: Admin Email Adresse
    description: "The email adresse for initial admin"
    value: admin@sentry.local
    required: true
  - name: ADMIN_PASSWORD
    displayName: Admin Password
    description: "The password for initial admin"
    generate: expression
    from: "[a-zA-Z0-9]{10}"
    required: true
  - name: SERVICE_ACCOUNT_NAME
    displayName: Service Account Name with `anyuid`
    description: "Specification of a serviceaccount which has an Security Context Constraints (scc) of `anyuid`, since some containers require root privileges."
    value: "useroot"
    required: true
  # Postgres
  - name: SENTRY_POSTGRES_HOST
    value: "postgres"
  - name: SENTRY_POSTGRES_PORT
    value: ""
  - name: SENTRY_DB_NAME
    value: "postgres"
  - name: SENTRY_DB_USER
    value: "postgres"
  - name: SENTRY_DB_PASSWORD
    value: ""
  # Mail
  - name: SENTRY_EMAIL_HOST
    value: "mail.sentry.local"
  - name: SENTRY_EMAIL_PORT
    value: "25"
  - name: SENTRY_EMAIL_USER
    value: ""
  - name: SENTRY_EMAIL_PASSWORD
    value: ""
  - name: SENTRY_EMAIL_USE_TLS
    value: "False"
  - name: SENTRY_SERVER_EMAIL
    value: "root@localhost"
  - name: SENTRY_MAILGUN_API_KEY
    value: ""
  - name: SENTRY_SMTP_HOSTNAME
    value: ""
  # OpenID Connect
  - name: OIDC_CLIENT_ID
    value: ""
  - name: OIDC_CLIENT_SECRET
    value: ""
  - name: OIDC_SCOPE
    value: "openid email"
  - name: OIDC_DOMAIN
    value: ""
    description: |
      defines where the OIDC configuration is going to be pulled from. 
      If your provider doesn't support the OIDC_DOMAIN, then you have to set these required endpoints by yourself (autorization_endpoint, token_endpoint, userinfo_endpoint, issuer).
  - name: OIDC_AUTHORIZATION_ENDPOINT
    value: ""
  - name: OIDC_TOKEN_ENDPOINT
    value: ""
  - name: OIDC_USERINFO_ENDPOINT
    value: ""
  - name: OIDC_ISSUER
    value: ""
    description: |
      You can also define OIDC_ISSUER to change the default provider name in the UI, even when the OIDC_DOMAIN is set.
      Else the displayed name can be a ugly URL.
objects:
  - apiVersion: v1
    kind: ConfigMap
    metadata:
      name: "sentry-config"
    data:
      SENTRY_EVENT_RETENTION_DAYS: "90"
  - apiVersion: v1
    kind: ConfigMap
    metadata:
      name: "sentry-snuba-config"
    data:
      CLICKHOUSE_HOST: clickhouse
      CLICKHOUSE_PORT: "9000"
      DEFAULT_BROKERS: kafka-service:9092
      REDIS_HOST: redis
      REDIS_PORT: "6379"
      SNUBA_SETTINGS: docker
      UWSGI_DISABLE_LOGGING: "true"
      UWSGI_MAX_REQUESTS: "10000"
  - apiVersion: v1
    kind: Secret
    metadata:
      name: "sentry-secret"
    type: Opaque
    stringData:
      SENTRY_POSTGRES_HOST: "${SENTRY_POSTGRES_HOST}"
      SENTRY_POSTGRES_PORT: "${SENTRY_POSTGRES_PORT}"
      SENTRY_DB_NAME: "${SENTRY_DB_NAME}"
      SENTRY_DB_USER: "${SENTRY_DB_USER}"
      SENTRY_DB_PASSWORD: "${SENTRY_DB_PASSWORD}"
      SENTRY_SECRET_KEY: "${SENTRY_SECRET_KEY}"
      SENTRY_EMAIL_HOST: "${SENTRY_EMAIL_HOST}"
      SENTRY_EMAIL_PASSWORD: "${SENTRY_EMAIL_PASSWORD}"
      SENTRY_EMAIL_USER: "${SENTRY_EMAIL_USER}"
      SENTRY_EMAIL_PORT: "${SENTRY_EMAIL_PORT}"
      SENTRY_EMAIL_USE_TLS: "${SENTRY_EMAIL_USE_TLS}"
      SENTRY_SERVER_EMAIL: "${SENTRY_SERVER_EMAIL}"
      SENTRY_MAILGUN_API_KEY: "${SENTRY_MAILGUN_API_KEY}"
      SENTRY_SMTP_HOSTNAME: "${SENTRY_SMTP_HOSTNAME}"
      OIDC_CLIENT_ID: "${OIDC_CLIENT_ID}"
      OIDC_CLIENT_SECRET: "${OIDC_CLIENT_SECRET}"
      OIDC_SCOPE: "${OIDC_SCOPE}"
      OIDC_DOMAIN: "${OIDC_DOMAIN}"
      OIDC_AUTHORIZATION_ENDPOINT: "${OIDC_AUTHORIZATION_ENDPOINT}"
      OIDC_TOKEN_ENDPOINT: "${OIDC_TOKEN_ENDPOINT}"
      OIDC_USERINFO_ENDPOINT: "${OIDC_USERINFO_ENDPOINT}"
      OIDC_ISSUER: "${OIDC_ISSUER}"
  - apiVersion: v1
    kind: ImageStream
    metadata:
      annotations:
        openshift.io/display-name: internal-sentry
        io.sentry.plugins: "sentry-auth-oidc, sentry-msteams"
      labels:
        io.sentry.service: sentry
      name: internal-sentry
    spec:
      lookupPolicy:
        local: true
      tags:
        - annotations:
            io.sentry.plugins: "sentry-auth-oidc, sentry-msteams"
            openshift.io/display-name: internal-sentry
          from:
            kind: DockerImage
            name: internal-sentry:latest
          importPolicy: {}
          name: latest
  - apiVersion: build.openshift.io/v1
    kind: BuildConfig
    metadata:
      annotations:
        description: "Sentry On-Premise Build"
        io.sentry.plugins: "sentry-auth-oidc, sentry-msteams"
      name: internal-sentry
    spec:
      failedBuildsHistoryLimit: 5
      nodeSelector: null
      output:
        to:
          kind: ImageStreamTag
          name: "internal-sentry:latest"
      postCommit: {}
      resources: {}
      runPolicy: Serial
      source:
        contextDir: "/openshift/sentry"
        git:
          uri: >-
            https://github.com/SimonGolms/sentry-onpremise-openshift.git
        #sourceSecret:
        #  name: cd-user-token
        type: Git
      strategy:
        dockerStrategy:
          env:
            - name: OIDC_CLIENT_ID
              valueFrom:
                secretKeyRef:
                  key: OIDC_CLIENT_ID
                  name: "sentry-secret"
            - name: OIDC_CLIENT_SECRET
              valueFrom:
                secretKeyRef:
                  key: OIDC_CLIENT_SECRET
                  name: "sentry-secret"
            - name: OIDC_SCOPE
              valueFrom:
                secretKeyRef:
                  key: OIDC_SCOPE
                  name: "sentry-secret"
            - name: OIDC_DOMAIN
              valueFrom:
                secretKeyRef:
                  key: OIDC_DOMAIN
                  name: "sentry-secret"
            - name: OIDC_AUTHORIZATION_ENDPOINT
              valueFrom:
                secretKeyRef:
                  key: OIDC_AUTHORIZATION_ENDPOINT
                  name: "sentry-secret"
            - name: OIDC_TOKEN_ENDPOINT
              valueFrom:
                secretKeyRef:
                  key: OIDC_TOKEN_ENDPOINT
                  name: "sentry-secret"
            - name: OIDC_USERINFO_ENDPOINT
              valueFrom:
                secretKeyRef:
                  key: OIDC_USERINFO_ENDPOINT
                  name: "sentry-secret"
            - name: OIDC_ISSUER
              valueFrom:
                secretKeyRef:
                  key: OIDC_ISSUER
                  name: "sentry-secret"
            - name: SENTRY_EVENT_RETENTION_DAYS
              valueFrom:
                configMapKeyRef:
                  key: SENTRY_EVENT_RETENTION_DAYS
                  name: "sentry-config"
            - name: SENTRY_EMAIL_HOST
              valueFrom:
                secretKeyRef:
                  key: SENTRY_EMAIL_HOST
                  name: "sentry-secret"
            - name: SENTRY_EMAIL_PASSWORD
              valueFrom:
                secretKeyRef:
                  key: SENTRY_EMAIL_PASSWORD
                  name: "sentry-secret"
            - name: SENTRY_EMAIL_USER
              valueFrom:
                secretKeyRef:
                  key: SENTRY_EMAIL_USER
                  name: "sentry-secret"
            - name: SENTRY_EMAIL_PORT
              valueFrom:
                secretKeyRef:
                  key: SENTRY_EMAIL_PORT
                  name: "sentry-secret"
            - name: SENTRY_EMAIL_USE_TLS
              valueFrom:
                secretKeyRef:
                  key: SENTRY_EMAIL_USE_TLS
                  name: "sentry-secret"
            - name: SENTRY_SERVER_EMAIL
              valueFrom:
                secretKeyRef:
                  key: SENTRY_SERVER_EMAIL
                  name: "sentry-secret"
            - name: SENTRY_MAILGUN_API_KEY
              valueFrom:
                secretKeyRef:
                  key: SENTRY_MAILGUN_API_KEY
                  name: "sentry-secret"
            - name: SENTRY_POSTGRES_HOST
              valueFrom:
                secretKeyRef:
                  key: SENTRY_POSTGRES_HOST
                  name: "sentry-secret"
            - name: SENTRY_POSTGRES_PORT
              valueFrom:
                secretKeyRef:
                  key: SENTRY_POSTGRES_PORT
                  name: "sentry-secret"
            - name: SENTRY_DB_NAME
              valueFrom:
                secretKeyRef:
                  key: SENTRY_DB_NAME
                  name: "sentry-secret"
            - name: SENTRY_DB_USER
              valueFrom:
                secretKeyRef:
                  key: SENTRY_DB_USER
                  name: "sentry-secret"
            - name: SENTRY_DB_PASSWORD
              valueFrom:
                secretKeyRef:
                  key: SENTRY_DB_PASSWORD
                  name: "sentry-secret"
        type: Docker
      successfulBuildsHistoryLimit: 5
      triggers:
        - type: ConfigChange
  - apiVersion: v1
    kind: PersistentVolumeClaim
    metadata:
      creationTimestamp: null
      labels:
        io.sentry.service: sentry-secrets
      name: sentry-secrets
    spec:
      accessModes:
        - ReadWriteOnce
      resources:
        requests:
          storage: 100Mi
    status: {}
  - apiVersion: v1
    kind: Service
    metadata:
      annotations:
      creationTimestamp: null
      labels:
        io.sentry.service: clickhouse
      name: clickhouse
    spec:
      ports:
        - name: "8123"
          port: 8123
          targetPort: 8123
        - name: "9000"
          port: 9000
          targetPort: 9000
        - name: "9009"
          port: 9009
          targetPort: 9009
      selector:
        io.sentry.service: clickhouse
    status:
      loadBalancer: {}
  - apiVersion: v1
    kind: Service
    metadata:
      annotations:
      creationTimestamp: null
      labels:
        io.sentry.service: cron
      name: cron
    spec:
      ports:
        - name: "9000"
          port: 9000
          targetPort: 9000
      selector:
        io.sentry.service: cron
    status:
      loadBalancer: {}
  - apiVersion: v1
    kind: Service
    metadata:
      annotations:
      creationTimestamp: null
      labels:
        io.sentry.service: kafka
      name: kafka-service
    spec:
      ports:
        - name: "9092"
          port: 9092
      selector:
        io.sentry.service: kafka
    status:
      loadBalancer: {}
  - apiVersion: v1
    kind: Service
    metadata:
      annotations:
      creationTimestamp: null
      labels:
        io.sentry.service: memcached
      name: memcached
    spec:
      ports:
        - name: "11211"
          port: 11211
          targetPort: 11211
      selector:
        io.sentry.service: memcached
    status:
      loadBalancer: {}
  - apiVersion: v1
    kind: Service
    metadata:
      annotations:
      creationTimestamp: null
      labels:
        io.sentry.service: post-process-forwarder
      name: post-process-forwarder
    spec:
      ports:
        - name: "9000"
          port: 9000
          targetPort: 9000
      selector:
        io.sentry.service: post-process-forwarder
    status:
      loadBalancer: {}
  - apiVersion: v1
    kind: Service
    metadata:
      annotations:
      creationTimestamp: null
      labels:
        io.sentry.service: postgres
      name: postgres
    spec:
      ports:
        - name: "5432"
          port: 5432
          targetPort: 5432
      selector:
        io.sentry.service: postgres
    status:
      loadBalancer: {}
  - apiVersion: v1
    kind: Service
    metadata:
      annotations:
      creationTimestamp: null
      labels:
        io.sentry.service: redis
      name: redis
    spec:
      ports:
        - name: "6379"
          port: 6379
          targetPort: 6379
      selector:
        io.sentry.service: redis
    status:
      loadBalancer: {}
  - apiVersion: v1
    kind: Service
    metadata:
      annotations:
      creationTimestamp: null
      labels:
        io.sentry.service: smtp
      name: smtp
    spec:
      ports:
        - name: "25"
          port: 25
          targetPort: 25
      selector:
        io.sentry.service: smtp
    status:
      loadBalancer: {}
  - apiVersion: v1
    kind: Service
    metadata:
      annotations:
      creationTimestamp: null
      labels:
        io.sentry.service: snuba-api
      name: snuba-api
    spec:
      ports:
        - name: "1218"
          port: 1218
          targetPort: 1218
      selector:
        io.sentry.service: snuba-api
    status:
      loadBalancer: {}
  - apiVersion: v1
    kind: Service
    metadata:
      annotations:
      creationTimestamp: null
      labels:
        io.sentry.service: snuba-consumer
      name: snuba-consumer
    spec:
      ports:
        - name: "1218"
          port: 1218
          targetPort: 1218
      selector:
        io.sentry.service: snuba-consumer
    status:
      loadBalancer: {}
  - apiVersion: v1
    kind: Service
    metadata:
      annotations:
      creationTimestamp: null
      labels:
        io.sentry.service: snuba-outcomes-consumer
      name: snuba-outcomes-consumer
    spec:
      ports:
        - name: "1218"
          port: 1218
          targetPort: 1218
      selector:
        io.sentry.service: snuba-outcomes-consumer
    status:
      loadBalancer: {}
  - apiVersion: v1
    kind: Service
    metadata:
      annotations:
      creationTimestamp: null
      labels:
        io.sentry.service: snuba-sessions-consumer
      name: snuba-sessions-consumer
    spec:
      ports:
        - name: "1218"
          port: 1218
          targetPort: 1218
      selector:
        io.sentry.service: snuba-sessions-consumer
    status:
      loadBalancer: {}
  - apiVersion: v1
    kind: Service
    metadata:
      annotations:
      creationTimestamp: null
      labels:
        io.sentry.service: snuba-transactions-consumer
      name: snuba-transactions-consumer
    spec:
      ports:
        - name: "1218"
          port: 1218
          targetPort: 1218
      selector:
        io.sentry.service: snuba-transactions-consumer
    status:
      loadBalancer: {}
  - apiVersion: v1
    kind: Service
    metadata:
      annotations:
      creationTimestamp: null
      labels:
        io.sentry.service: snuba-replacer
      name: snuba-replacer
    spec:
      ports:
        - name: "1218"
          port: 1218
          targetPort: 1218
      selector:
        io.sentry.service: snuba-replacer
    status:
      loadBalancer: {}
  - apiVersion: v1
    kind: Service
    metadata:
      annotations:
      creationTimestamp: null
      labels:
        io.sentry.service: symbolicator
      name: symbolicator
    spec:
      ports:
        - name: "3021"
          port: 3021
          targetPort: 3021
      selector:
        io.sentry.service: symbolicator
    status:
      loadBalancer: {}
  - apiVersion: v1
    kind: Service
    metadata:
      annotations:
      creationTimestamp: null
      labels:
        io.sentry.service: web
      name: web
    spec:
      ports:
        - name: "9000"
          port: 9000
          targetPort: 9000
      selector:
        io.sentry.service: web
    status:
      loadBalancer: {}
  - apiVersion: v1
    kind: Service
    metadata:
      annotations:
      creationTimestamp: null
      labels:
        io.sentry.service: nginx
      name: nginx
    spec:
      ports:
        - name: "80"
          port: 80
          targetPort: 80
      selector:
        io.sentry.service: nginx
    status:
      loadBalancer: {}
  - apiVersion: v1
    kind: Service
    metadata:
      annotations:
      creationTimestamp: null
      labels:
        io.sentry.service: relay
      name: relay
    spec:
      ports:
        - name: "3000"
          port: 3000
          targetPort: 3000
      selector:
        io.sentry.service: relay
    status:
      loadBalancer: {}
  - apiVersion: v1
    kind: Service
    metadata:
      annotations:
      creationTimestamp: null
      labels:
        io.sentry.service: worker
      name: worker
    spec:
      ports:
        - name: "9000"
          port: 9000
          targetPort: 9000
      selector:
        io.sentry.service: worker
    status:
      loadBalancer: {}
  - apiVersion: v1
    kind: Service
    metadata:
      annotations:
      creationTimestamp: null
      labels:
        io.sentry.service: ingest-consumer
      name: ingest-consumer
    spec:
      ports:
        - name: "9000"
          port: 9000
          targetPort: 9000
      selector:
        io.sentry.service: ingest-consumer
    status:
      loadBalancer: {}
  - apiVersion: v1
    kind: Service
    metadata:
      annotations:
      creationTimestamp: null
      labels:
        io.sentry.service: zookeeper
      name: zookeeper
    spec:
      ports:
        - name: "2181"
          port: 2181
          targetPort: 2181
        - name: "2888"
          port: 2888
          targetPort: 2888
        - name: "3888"
          port: 3888
          targetPort: 3888
      selector:
        io.sentry.service: zookeeper
    status:
      loadBalancer: {}
  - apiVersion: v1
    kind: DeploymentConfig
    metadata:
      annotations:
      creationTimestamp: null
      labels:
        io.sentry.service: web
      name: web
    spec:
      replicas: 1
      selector:
        io.sentry.service: web
      strategy:
        activeDeadlineSeconds: 21600
        resources: {}
        rollingParams:
          intervalSeconds: 1
          maxSurge: 25%
          maxUnavailable: 25%
          timeoutSeconds: 1000
          updatePeriodSeconds: 1
        type: Rolling
      template:
        metadata:
          creationTimestamp: null
          labels:
            io.sentry.service: web
        spec:
          containers:
            - env:
                - name: SENTRY_CONF
                  value: '/etc/sentry'
                - name: SNUBA
                  value: http://snuba-api:1218
              envFrom:
                - configMapRef:
                    name: "sentry-config"
                - secretRef:
                    name: "sentry-secret"
              image: " "
              name: web
              ports:
                - containerPort: 9000
              resources: {}
              volumeMounts:
                - mountPath: /data
                  name: sentry-data
                - mountPath: /etc/sentry
                  name: sentry-conf
          initContainers:
            - name: init-sentry-config
              image: "busybox:1.28.4"
              command: ["sh", "-c", "until [ -f /etc/sentry/config.yml ] && [ -f /etc/sentry/sentry.conf.py ] && [ -f /etc/sentry/requirements.txt ]; do echo waiting for config; sleep 2; done;"]
              volumeMounts:
                - mountPath: /etc/sentry
                  name: sentry-conf
            - name: init-redis
              image: "busybox:1.28.4"
              command: ["sh", "-c", "until nslookup redis; do echo waiting for redis; sleep 2; done;"]
            - name: init-postgres
              image: "busybox:1.28.4"
              command: ["sh", "-c", "until nslookup postgres; do echo waiting for postgres; sleep 2; done;"]
            - name: init-memcached
              image: "busybox:1.28.4"
              command: ["sh", "-c", "until nslookup memcached; do echo waiting for memcached; sleep 2; done;"]
            - name: init-smtp
              image: "busybox:1.28.4"
              command: ["sh", "-c", "until nslookup smtp; do echo waiting for smtp; sleep 2; done;"]
            - name: init-snuba-api
              image: "busybox:1.28.4"
              command: ["sh", "-c", "until nslookup snuba-api; do echo waiting for snuba-api; sleep 2; done;"]
            - name: init-snuba-consumer
              image: "busybox:1.28.4"
              command: ["sh", "-c", "until nslookup snuba-consumer; do echo waiting for snuba-consumer; sleep 2; done;"]
            - name: init-snuba-outcomes-consumer
              image: "busybox:1.28.4"
              command: ["sh", "-c", "until nslookup snuba-outcomes-consumer; do echo waiting for snuba-outcomes-consumer; sleep 2; done;"]
            - name: init-snuba-sessions-consumer
              image: "busybox:1.28.4"
              command: ["sh", "-c", "until nslookup snuba-sessions-consumer; do echo waiting for snuba-sessions-consumer; sleep 2; done;"]
            - name: init-snuba-transactions-consumer
              image: "busybox:1.28.4"
              command: ["sh", "-c", "until nslookup snuba-transactions-consumer; do echo waiting for snuba-transactions-consumer; sleep 2; done;"]
            - name: init-snuba-replacer
              image: "busybox:1.28.4"
              command: ["sh", "-c", "until nslookup snuba-replacer; do echo waiting for snuba-replacer; sleep 2; done;"]
            - name: init-symbolicator
              image: "busybox:1.28.4"
              command: ["sh", "-c", "until nslookup symbolicator; do echo waiting for symbolicator; sleep 2; done;"]
            - name: init-kafka
              image: "busybox:1.28.4"
              command: ["sh", "-c", "until nslookup kafka-service; do echo waiting for kafka-service; sleep 2; done;"]
            - name: init-clickhouse
              image: "busybox:1.28.4"
              command: ["sh", "-c", "until nslookup clickhouse; do echo waiting for clickhouse; sleep 2; done;"]
            - name: init-clickhouse-client
              image: "yandex/clickhouse-server:19.4"
              command: ["sh", "-c", 'clickhouse client -h clickhouse --query="SHOW TABLES;" | grep sentry_local && exit 0']
            - name: init-web-upgrade
              env:
                - name: SENTRY_CONF
                  value: '/etc/sentry'
                - name: SNUBA
                  value: http://snuba-api:1218
              envFrom:
                - configMapRef:
                    name: "sentry-config"
                - secretRef:
                    name: "sentry-secret"
              image: "internal-sentry"
              args: ["sentry upgrade --noinput"]
              volumeMounts:
                - mountPath: /data
                  name: sentry-data
                - mountPath: /etc/sentry
                  name: sentry-conf
            - name: init-file-storage-migrate
              env:
              - name: SENTRY_CONF
                value: '/etc/sentry'
              - name: SNUBA
                value: http://snuba-api:1218
              envFrom: 
              - configMapRef:
                  name: sentry-config
              - secretRef:
                  name: sentry-secret
              image: "internal-sentry"
              command: ["sh", "-c", "mkdir -p /tmp/files; mv /data/* /tmp/files/; mv /tmp/files /data/files; chown -R sentry:sentry /data"]
              volumeMounts:
                - mountPath: /data
                  name: sentry-data
                - mountPath: /etc/sentry
                  name: sentry-conf
          restartPolicy: Always
          serviceAccountName: "${SERVICE_ACCOUNT_NAME}"
          volumes:
            - name: sentry-data
              persistentVolumeClaim:
                claimName: sentry-data
            - name: sentry-conf
              persistentVolumeClaim:
                claimName: sentry-conf
      test: false
      triggers:
        - type: ConfigChange
        - imageChangeParams:
            automatic: true
            containerNames:
              - web
            from:
              kind: ImageStreamTag
              name: "internal-sentry:latest"
          type: ImageChange
    status: {}
  - apiVersion: v1
    kind: PersistentVolumeClaim
    metadata:
      creationTimestamp: null
      labels:
        io.sentry.service: sentry-data
      name: sentry-data
    spec:
      accessModes:
        - ReadWriteOnce
      resources:
        requests:
          storage: 60Gi
    status: {}
  - apiVersion: batch/v1
    kind: Job
    metadata:
      annotations:
        template.alpha.openshift.io/wait-for-ready: "true"
      name: sentry-get-sentry-config
      labels:
        component: sentry
    spec:
      selector: {}
      template:
        metadata:
          name: sentry-get-sentry-config
          labels:
            component: sentry
        spec:
          containers:
            - name: sentry-get-sentry-config
              image: "curlimages/curl:latest"
              args:
                - -L 
                - "https://raw.githubusercontent.com/SimonGolms/sentry-onpremise-openshift/master/openshift/sentry/{config.yml,sentry.conf.py,requirements.txt}"
                - -o 
                - "/etc/sentry/#1"
              volumeMounts:
                - mountPath: /etc/sentry
                  name: sentry-conf
              env:
                - name: http_proxy
                  value: "${HTTP_PROXY}"
                - name: https_proxy
                  value: "${HTTPS_PROXY}"
                - name: no_proxy
                  value: "${NO_PROXY}"
              securityContext:
                privileged: true
          restartPolicy: OnFailure
          volumes:
            - name: sentry-conf
              persistentVolumeClaim:
                claimName: sentry-conf
  - apiVersion: v1
    kind: PersistentVolumeClaim
    metadata:
      creationTimestamp: null
      labels:
        io.sentry.service: sentry-conf
      name: sentry-conf
    spec:
      accessModes:
        - ReadWriteOnce
      resources:
        requests:
          storage: 100Mi
    status: {}
  - apiVersion: batch/v1
    kind: Job
    metadata:
      annotations:
        template.alpha.openshift.io/wait-for-ready: "true"
      name: sentry-createuser
      labels:
        component: sentry
    spec:
      selector: {}
      template:
        metadata:
          name: sentry-createuser
          labels:
            component: sentry
        spec:
          initContainers:
            - name: init-sentry-config
              image: "busybox:1.28.4"
              command: ["sh", "-c", "until [ -f /etc/sentry/config.yml ] && [ -f /etc/sentry/sentry.conf.py ] && [ -f /etc/sentry/requirements.txt ]; do echo waiting for config; sleep 2; done;"]
              volumeMounts:
                - mountPath: /etc/sentry
                  name: sentry-conf
            - name: init-web
              image: "busybox:1.28.4"
              command: ["sh", "-c", "until nslookup web; do echo waiting for web; sleep 2; done;"]
            # ? Only to be sure migrations has run before
            - name: init-web-upgrade
              env:
                - name: SENTRY_CONF
                  value: '/etc/sentry'
                - name: SNUBA
                  value: http://snuba-api:1218
              envFrom:
                - configMapRef:
                    name: "sentry-config"
                - secretRef:
                    name: "sentry-secret"
              image: "internal-sentry"
              args: ["sentry upgrade --noinput"]
              volumeMounts:
                - mountPath: /data
                  name: sentry-data
                - mountPath: /etc/sentry
                  name: sentry-conf
          containers:
            - name: web
              image: "internal-sentry"
              args:
                - createuser
                - --no-input
                - --email
                - ${ADMIN_USERNAME}
                - --password
                - ${ADMIN_PASSWORD}
                - --superuser
              volumeMounts:
                - mountPath: /data
                  name: sentry-data
                - mountPath: /etc/sentry
                  name: sentry-conf
              env:
                - name: ADMIN_USERNAME
                  value: "${ADMIN_USERNAME}"
                - name: ADMIN_PASSWORD
                  value: "${ADMIN_PASSWORD}"
                - name: SENTRY_CONF
                  value: '/etc/sentry'
                - name: SNUBA
                  value: http://snuba-api:1218
              envFrom:
                - configMapRef:
                    name: "sentry-config"
                - secretRef:
                    name: "sentry-secret"
          restartPolicy: OnFailure
          volumes:
            - name: sentry-data
              persistentVolumeClaim:
                claimName: sentry-data
            - name: sentry-conf
              persistentVolumeClaim:
                claimName: sentry-conf
  - apiVersion: batch/v1beta1
    kind: CronJob
    metadata:
      name: sentry-cleanup
      labels:
        component: sentry
    spec:
      schedule: "0 0 * * *"
      concurrencyPolicy: Allow
      suspend: false
      successfulJobsHistoryLimit: 3
      failedJobsHistoryLimit: 1
      jobTemplate:
        spec:
          template:
            metadata:
              labels:
                component: sentry
            spec:
              containers:
                - name: sentry-cleanup
                  env:
                    - name: SENTRY_CONF
                      value: '/etc/sentry'
                    - name: SNUBA
                      value: http://snuba-api:1218
                  envFrom:
                    - configMapRef:
                        name: "sentry-config"
                    - secretRef:
                        name: "sentry-secret"
                  image: "internal-sentry"
                  command: ["sh", "-c", "sentry cleanup --days ${SENTRY_EVENT_RETENTION_DAYS}"]
                  volumeMounts:
                    - mountPath: /data
                      name: sentry-data
                    - mountPath: /etc/sentry
                      name: sentry-conf
              restartPolicy: Never
              volumes:
                - name: sentry-data
                  persistentVolumeClaim:
                    claimName: sentry-data
                - name: sentry-conf
                  persistentVolumeClaim:
                    claimName: sentry-conf
  - apiVersion: v1
    kind: DeploymentConfig
    metadata:
      annotations:
      creationTimestamp: null
      labels:
        io.sentry.service: post-process-forwarder
      name: post-process-forwarder
    spec:
      replicas: 1
      selector:
        io.sentry.service: post-process-forwarder
      strategy:
        resources: {}
        type: Recreate
      template:
        metadata:
          creationTimestamp: null
          labels:
            io.sentry.service: post-process-forwarder
        spec:
          initContainers:
            - name: init-sentry-config
              image: "busybox:1.28.4"
              command: ["sh", "-c", "until [ -f /etc/sentry/config.yml ] && [ -f /etc/sentry/sentry.conf.py ] && [ -f /etc/sentry/requirements.txt ]; do echo waiting for config; sleep 2; done;"]
              volumeMounts:
                - mountPath: /etc/sentry
                  name: sentry-conf
            - name: init-redis
              image: "busybox:1.28.4"
              command: ["sh", "-c", "until nslookup redis; do echo waiting for redis; sleep 2; done;"]
            - name: init-postgres
              image: "busybox:1.28.4"
              command: ["sh", "-c", "until nslookup postgres; do echo waiting for postgres; sleep 2; done;"]
            - name: init-memcached
              image: "busybox:1.28.4"
              command: ["sh", "-c", "until nslookup memcached; do echo waiting for memcached; sleep 2; done;"]
            - name: init-smtp
              image: "busybox:1.28.4"
              command: ["sh", "-c", "until nslookup smtp; do echo waiting for smtp; sleep 2; done;"]
            - name: init-snuba-api
              image: "busybox:1.28.4"
              command: ["sh", "-c", "until nslookup snuba-api; do echo waiting for snuba-api; sleep 2; done;"]
            - name: init-snuba-consumer
              image: "busybox:1.28.4"
              command: ["sh", "-c", "until nslookup snuba-consumer; do echo waiting for snuba-consumer; sleep 2; done;"]
            - name: init-snuba-outcomes-consumer
              image: "busybox:1.28.4"
              command: ["sh", "-c", "until nslookup snuba-outcomes-consumer; do echo waiting for snuba-outcomes-consumer; sleep 2; done;"]
            - name: init-snuba-sessions-consumer
              image: "busybox:1.28.4"
              command: ["sh", "-c", "until nslookup snuba-sessions-consumer; do echo waiting for snuba-sessions-consumer; sleep 2; done;"]
            - name: init-snuba-transactions-consumer
              image: "busybox:1.28.4"
              command: ["sh", "-c", "until nslookup snuba-transactions-consumer; do echo waiting for snuba-transactions-consumer; sleep 2; done;"]
            - name: init-snuba-replacer
              image: "busybox:1.28.4"
              command: ["sh", "-c", "until nslookup snuba-replacer; do echo waiting for snuba-replacer; sleep 2; done;"]
            - name: init-symbolicator
              image: "busybox:1.28.4"
              command: ["sh", "-c", "until nslookup symbolicator; do echo waiting for symbolicator; sleep 2; done;"]
            - name: init-kafka
              image: "busybox:1.28.4"
              command: ["sh", "-c", "until nslookup kafka-service; do echo waiting for kafka-service; sleep 2; done;"]
          containers:
            - args:
                - run
                - post-process-forwarder
                - --commit-batch-size
                - "1"
              env:
                - name: SENTRY_CONF
                  value: '/etc/sentry'
                - name: SNUBA
                  value: http://snuba-api:1218
              envFrom:
                - configMapRef:
                    name: "sentry-config"
                - secretRef:
                    name: "sentry-secret"
              image: " "
              name: post-process-forwarder
              ports:
                - containerPort: 9000
              resources: {}
              volumeMounts:
                - mountPath: /data
                  name: sentry-data
                - mountPath: /etc/sentry
                  name: sentry-conf
          restartPolicy: Always
          volumes:
            - name: sentry-data
              persistentVolumeClaim:
                claimName: sentry-data
            - name: sentry-conf
              persistentVolumeClaim:
                claimName: sentry-conf
      test: false
      triggers:
        - type: ConfigChange
        - imageChangeParams:
            automatic: true
            containerNames:
              - post-process-forwarder
            from:
              kind: ImageStreamTag
              name: "internal-sentry:latest"
          type: ImageChange
    status: {}
  - apiVersion: v1
    kind: DeploymentConfig
    metadata:
      annotations:
      creationTimestamp: null
      labels:
        io.sentry.service: worker
      name: worker
    spec:
      replicas: 1
      selector:
        io.sentry.service: worker
      strategy:
        resources: {}
        type: Recreate
      template:
        metadata:
          creationTimestamp: null
          labels:
            io.sentry.service: worker
        spec:
          initContainers:
            - name: init-sentry-config
              image: "busybox:1.28.4"
              command: ["sh", "-c", "until [ -f /etc/sentry/config.yml ] && [ -f /etc/sentry/sentry.conf.py ] && [ -f /etc/sentry/requirements.txt ]; do echo waiting for config; sleep 2; done;"]
              volumeMounts:
                - mountPath: /etc/sentry
                  name: sentry-conf
            - name: init-redis
              image: "busybox:1.28.4"
              command: ["sh", "-c", "until nslookup redis; do echo waiting for redis; sleep 2; done;"]
            - name: init-postgres
              image: "busybox:1.28.4"
              command: ["sh", "-c", "until nslookup postgres; do echo waiting for postgres; sleep 2; done;"]
            - name: init-memcached
              image: "busybox:1.28.4"
              command: ["sh", "-c", "until nslookup memcached; do echo waiting for memcached; sleep 2; done;"]
            - name: init-smtp
              image: "busybox:1.28.4"
              command: ["sh", "-c", "until nslookup smtp; do echo waiting for smtp; sleep 2; done;"]
            - name: init-snuba-api
              image: "busybox:1.28.4"
              command: ["sh", "-c", "until nslookup snuba-api; do echo waiting for snuba-api; sleep 2; done;"]
            - name: init-snuba-consumer
              image: "busybox:1.28.4"
              command: ["sh", "-c", "until nslookup snuba-consumer; do echo waiting for snuba-consumer; sleep 2; done;"]
            - name: init-snuba-outcomes-consumer
              image: "busybox:1.28.4"
              command: ["sh", "-c", "until nslookup snuba-outcomes-consumer; do echo waiting for snuba-outcomes-consumer; sleep 2; done;"]
            - name: init-snuba-sessions-consumer
              image: "busybox:1.28.4"
              command: ["sh", "-c", "until nslookup snuba-sessions-consumer; do echo waiting for snuba-sessions-consumer; sleep 2; done;"]
            - name: init-snuba-transactions-consumer
              image: "busybox:1.28.4"
              command: ["sh", "-c", "until nslookup snuba-transactions-consumer; do echo waiting for snuba-transactions-consumer; sleep 2; done;"]
            - name: init-snuba-replacer
              image: "busybox:1.28.4"
              command: ["sh", "-c", "until nslookup snuba-replacer; do echo waiting for snuba-replacer; sleep 2; done;"]
            - name: init-symbolicator
              image: "busybox:1.28.4"
              command: ["sh", "-c", "until nslookup symbolicator; do echo waiting for symbolicator; sleep 2; done;"]
            - name: init-kafka
              image: "busybox:1.28.4"
              command: ["sh", "-c", "until nslookup kafka-service; do echo waiting for kafka-service; sleep 2; done;"]
          containers:
            - args:
                - run
                - worker
              env:
                - name: SENTRY_CONF
                  value: '/etc/sentry'
                - name: SNUBA
                  value: http://snuba-api:1218
              envFrom:
                - configMapRef:
                    name: "sentry-config"
                - secretRef:
                    name: "sentry-secret"
              image: " "
              name: worker
              ports:
                - containerPort: 9000
              resources: {}
              volumeMounts:
                - mountPath: /data
                  name: sentry-data
                - mountPath: /etc/sentry
                  name: sentry-conf
          restartPolicy: Always
          serviceAccountName: "${SERVICE_ACCOUNT_NAME}"
          volumes:
            - name: sentry-data
              persistentVolumeClaim:
                claimName: sentry-data
            - name: sentry-conf
              persistentVolumeClaim:
                claimName: sentry-conf
      test: false
      triggers:
        - type: ConfigChange
        - imageChangeParams:
            automatic: true
            containerNames:
              - worker
            from:
              kind: ImageStreamTag
              name: "internal-sentry:latest"
          type: ImageChange
    status: {}
  - apiVersion: v1
    kind: DeploymentConfig
    metadata:
      annotations:
      creationTimestamp: null
      labels:
        io.sentry.service: ingest-consumer
      name: ingest-consumer
    spec:
      replicas: 1
      selector:
        io.sentry.service: ingest-consumer
      strategy:
        resources: {}
        type: Recreate
      template:
        metadata:
          creationTimestamp: null
          labels:
            io.sentry.service: ingest-consumer
        spec:
          initContainers:
            - name: init-sentry-config
              image: "busybox:1.28.4"
              command: ["sh", "-c", "until [ -f /etc/sentry/config.yml ] && [ -f /etc/sentry/sentry.conf.py ] && [ -f /etc/sentry/requirements.txt ]; do echo waiting for config; sleep 2; done;"]
              volumeMounts:
                - mountPath: /etc/sentry
                  name: sentry-conf
            - name: init-redis
              image: "busybox:1.28.4"
              command: ["sh", "-c", "until nslookup redis; do echo waiting for redis; sleep 2; done;"]
            - name: init-postgres
              image: "busybox:1.28.4"
              command: ["sh", "-c", "until nslookup postgres; do echo waiting for postgres; sleep 2; done;"]
            - name: init-memcached
              image: "busybox:1.28.4"
              command: ["sh", "-c", "until nslookup memcached; do echo waiting for memcached; sleep 2; done;"]
            - name: init-smtp
              image: "busybox:1.28.4"
              command: ["sh", "-c", "until nslookup smtp; do echo waiting for smtp; sleep 2; done;"]
            - name: init-snuba-api
              image: "busybox:1.28.4"
              command: ["sh", "-c", "until nslookup snuba-api; do echo waiting for snuba-api; sleep 2; done;"]
            - name: init-snuba-consumer
              image: "busybox:1.28.4"
              command: ["sh", "-c", "until nslookup snuba-consumer; do echo waiting for snuba-consumer; sleep 2; done;"]
            - name: init-snuba-outcomes-consumer
              image: "busybox:1.28.4"
              command: ["sh", "-c", "until nslookup snuba-outcomes-consumer; do echo waiting for snuba-outcomes-consumer; sleep 2; done;"]
            - name: init-snuba-sessions-consumer
              image: "busybox:1.28.4"
              command: ["sh", "-c", "until nslookup snuba-sessions-consumer; do echo waiting for snuba-sessions-consumer; sleep 2; done;"]
            - name: init-snuba-transactions-consumer
              image: "busybox:1.28.4"
              command: ["sh", "-c", "until nslookup snuba-transactions-consumer; do echo waiting for snuba-transactions-consumer; sleep 2; done;"]
            - name: init-snuba-replacer
              image: "busybox:1.28.4"
              command: ["sh", "-c", "until nslookup snuba-replacer; do echo waiting for snuba-replacer; sleep 2; done;"]
            - name: init-symbolicator
              image: "busybox:1.28.4"
              command: ["sh", "-c", "until nslookup symbolicator; do echo waiting for symbolicator; sleep 2; done;"]
            - name: init-kafka
              image: "busybox:1.28.4"
              command: ["sh", "-c", "until nslookup kafka-service; do echo waiting for kafka-service; sleep 2; done;"]
          containers:
            - args:
                - run
                - ingest-consumer
                - --all-consumer-types
              env:
                - name: SENTRY_CONF
                  value: '/etc/sentry'
                - name: SNUBA
                  value: http://snuba-api:1218
              envFrom:
                - configMapRef:
                    name: "sentry-config"
                - secretRef:
                    name: "sentry-secret"
              image: " "
              name: ingest-consumer
              ports:
                - containerPort: 9000
              resources: {}
              volumeMounts:
                - mountPath: /data
                  name: sentry-data
                - mountPath: /etc/sentry
                  name: sentry-conf
          restartPolicy: Always
          serviceAccountName: "${SERVICE_ACCOUNT_NAME}"
          volumes:
            - name: sentry-data
              persistentVolumeClaim:
                claimName: sentry-data
            - name: sentry-conf
              persistentVolumeClaim:
                claimName: sentry-conf
      test: false
      triggers:
        - type: ConfigChange
        - imageChangeParams:
            automatic: true
            containerNames:
              - ingest-consumer
            from:
              kind: ImageStreamTag
              name: "internal-sentry:latest"
          type: ImageChange
    status: {}
  - apiVersion: v1
    kind: DeploymentConfig
    metadata:
      annotations:
      creationTimestamp: null
      labels:
        io.sentry.service: nginx
      name: nginx
    spec:
      replicas: 1
      selector:
        io.sentry.service: nginx
      strategy:
        activeDeadlineSeconds: 21600
        resources: {}
        rollingParams:
          intervalSeconds: 1
          maxSurge: 25%
          maxUnavailable: 25%
          timeoutSeconds: 1000
          updatePeriodSeconds: 1
        type: Rolling
      template:
        metadata:
          creationTimestamp: null
          labels:
            io.sentry.service: nginx
        spec:
          containers:
            - image: "nginx:1.16"
              name: nginx
              ports:
                - containerPort: 9000
              resources: {}
              volumeMounts:
                - mountPath: /etc/nginx
                  name: sentry-nginx-conf
          initContainers:
            - name: init-nginx-config
              image: "busybox:1.28.4"
              command: ["sh", "-c", "until [ -f /etc/nginx/nginx.conf ]; do echo waiting for config; sleep 2; done;"]
              volumeMounts:
                - mountPath: /etc/nginx
                  name: sentry-nginx-conf
            - name: init-web
              image: "busybox:1.28.4"
              command: ["sh", "-c", "until nslookup web; do echo waiting for web; sleep 2; done;"]
            - name: init-relay
              image: "busybox:1.28.4"
              command: ["sh", "-c", "until nslookup relay; do echo waiting for relay; sleep 2; done;"]
          restartPolicy: Always
          serviceAccountName: "${SERVICE_ACCOUNT_NAME}"
          volumes:
            - name: sentry-nginx-conf
              persistentVolumeClaim:
                claimName: sentry-nginx-conf
      test: false
      triggers:
        - type: ConfigChange
    status: {}
  - apiVersion: batch/v1
    kind: Job
    metadata:
      annotations:
        template.alpha.openshift.io/wait-for-ready: "true"
      name: sentry-get-nginx-config
      labels:
        component: sentry
    spec:
      selector: {}
      template:
        metadata:
          name: sentry-get-nginx-config
          labels:
            component: sentry
        spec:
          containers:
            - name: sentry-get-nginx-config
              image: "curlimages/curl:latest"
              args:
                - -L 
                - "https://raw.githubusercontent.com/SimonGolms/sentry-onpremise-openshift/master/openshift/nginx/nginx.conf"
                - -o 
                - "/etc/nginx/nginx.conf"
              volumeMounts:
                - mountPath: /etc/nginx
                  name: sentry-nginx-conf
              env:
                - name: http_proxy
                  value: "${HTTP_PROXY}"
                - name: https_proxy
                  value: "${HTTPS_PROXY}"
                - name: no_proxy
                  value: "${NO_PROXY}"
              securityContext:
                privileged: true
          restartPolicy: OnFailure
          volumes:
            - name: sentry-nginx-conf
              persistentVolumeClaim:
                claimName: sentry-nginx-conf
  - apiVersion: v1
    kind: PersistentVolumeClaim
    metadata:
      creationTimestamp: null
      labels:
        io.sentry.service: sentry-nginx-conf
      name: sentry-nginx-conf
    spec:
      accessModes:
        - ReadWriteOnce
      resources:
        requests:
          storage: 100Mi
    status: {}
  - apiVersion: v1
    kind: DeploymentConfig
    metadata:
      annotations:
      creationTimestamp: null
      labels:
        io.sentry.service: relay
      name: relay
    spec:
      replicas: 1
      selector:
        io.sentry.service: relay
      strategy:
        activeDeadlineSeconds: 21600
        resources: {}
        rollingParams:
          intervalSeconds: 1
          maxSurge: 25%
          maxUnavailable: 25%
          timeoutSeconds: 1000
          updatePeriodSeconds: 1
        type: Rolling
      template:
        metadata:
          creationTimestamp: null
          labels:
            io.sentry.service: relay
        spec:
          containers:
            - image: "getsentry/relay:latest"
              name: relay
              ports:
                - containerPort: 3000
              env: 
                # ugly fix because openshift/kubernetes automatically sets this to tcp://some.ip.adress:3000... I don't know why...
                # See: https://forum.sentry.io/t/getsentry-relay-not-accepting-config-file/10693/4
                - name: RELAY_PORT
                  value: "3000"
              resources: {}
              volumeMounts:
                - mountPath: /work/.relay
                  name: sentry-relay-conf
          initContainers:
            - name: init-relay-config
              image: "busybox:1.28.4"
              command: ["sh", "-c", "until [ -f /work/.relay/config.yml ] && [ -f  /work/.relay/credentials.json ]; do echo waiting for config; sleep 2; done;"]
              volumeMounts:
                - mountPath: /work/.relay
                  name: sentry-relay-conf
            - name: init-kafka
              image: "busybox:1.28.4"
              command: ["sh", "-c", "until nslookup kafka-service; do echo waiting for kafka-service; sleep 2; done;"]
            - name: init-redis
              image: "busybox:1.28.4"
              command: ["sh", "-c", "until nslookup redis; do echo waiting for redis; sleep 2; done;"]
            - name: init-web
              image: "busybox:1.28.4"
              command: ["sh", "-c", "until nslookup web; do echo waiting for web; sleep 2; done;"]
          restartPolicy: Always
          serviceAccountName: "${SERVICE_ACCOUNT_NAME}"
          volumes:
            - name: sentry-relay-conf
              persistentVolumeClaim:
                claimName: sentry-relay-conf
      test: false
      triggers:
        - type: ConfigChange
    status: {}
  - apiVersion: batch/v1
    kind: Job
    metadata:
      annotations:
        template.alpha.openshift.io/wait-for-ready: "true"
      name: sentry-get-relay-config
      labels:
        component: sentry
    spec:
      selector: {}
      template:
        metadata:
          name: sentry-get-relay-config
          labels:
            component: sentry
        spec:
          containers:
            - name: sentry-get-relay-config
              image: "curlimages/curl:latest"
              args:
                - -L 
                - "https://raw.githubusercontent.com/SimonGolms/sentry-onpremise-openshift/master/openshift/relay/config.yml"
                - -o 
                - "/work/.relay/config.yml"
              volumeMounts:
                - mountPath: /work/.relay
                  name: sentry-relay-conf
              env:
                - name: http_proxy
                  value: "${HTTP_PROXY}"
                - name: https_proxy
                  value: "${HTTPS_PROXY}"
                - name: no_proxy
                  value: "${NO_PROXY}"
              securityContext:
                privileged: true
          restartPolicy: OnFailure
          volumes:
            - name: sentry-relay-conf
              persistentVolumeClaim:
                claimName: sentry-relay-conf
  - apiVersion: batch/v1
    kind: Job
    metadata:
      annotations:
        template.alpha.openshift.io/wait-for-ready: "true"
      name: sentry-get-relay-credentials
      labels:
        component: sentry
    spec:
      selector: {}
      template:
        metadata:
          name: sentry-get-relay-credentials
          labels:
            component: sentry
        spec:
          initContainers:
            - name: init-relay-config
              image: "busybox:1.28.4"
              command: ["sh", "-c", "until [ -f /work/.relay/config.yml ]; do echo waiting for config; sleep 2; done;"]
              volumeMounts:
                - mountPath: /work/.relay
                  name: sentry-relay-conf
          containers:
            - name: sentry-get-relay-credentials
              image: "getsentry/relay:latest"
              command: 
                - /bin/bash
              args:
                # really ugly workaround. the rely cmd wants to read the credentials.json which was generated by the redirect in the end and is empty at this time.
                # that's why I had to insert the sleep and the workaround with the env var.
                - -c
                - "CRED=$(relay credentials generate --stdout); sleep 5; [[ ! -z \"$CRED\" ]] && echo $CRED > /work/.relay/credentials.json"
              env: 
                # ugly fix because openshift/kubernetes automatically sets this to tcp://some.ip.adress:3000... I don't know why...
                # See: https://forum.sentry.io/t/getsentry-relay-not-accepting-config-file/10693/4
                - name: RELAY_PORT
                  value: "3000"
              volumeMounts:
                - mountPath: /work/.relay
                  name: sentry-relay-conf
          restartPolicy: OnFailure
          volumes:
            - name: sentry-relay-conf
              persistentVolumeClaim:
                claimName: sentry-relay-conf
  - apiVersion: v1
    kind: PersistentVolumeClaim
    metadata:
      creationTimestamp: null
      labels:
        io.sentry.service: sentry-relay-conf
      name: sentry-relay-conf
    spec:
      accessModes:
        - ReadWriteOnce
      resources:
        requests:
          storage: 100Mi
    status: {}
  - apiVersion: v1
    kind: DeploymentConfig
    metadata:
      annotations:
      creationTimestamp: null
      labels:
        io.sentry.service: clickhouse
      name: clickhouse
    spec:
      replicas: 1
      selector:
        io.sentry.service: clickhouse
      strategy:
        resources: {}
        type: Recreate
      template:
        metadata:
          creationTimestamp: null
          labels:
            io.sentry.service: clickhouse
        spec:
          containers:
            - image: "yandex/clickhouse-server:20.3.9.70"
              name: clickhouse
              ports:
                - containerPort: 8123
                - containerPort: 9000
                - containerPort: 9009
              resources: {}
              volumeMounts:
                - mountPath: /var/lib/clickhouse
                  name: sentry-clickhouse
                - mountPath: /var/log/clickhouse-server
                  name: sentry-clickhouse-log
          restartPolicy: Always
          serviceAccountName: "${SERVICE_ACCOUNT_NAME}"
          volumes:
            - name: sentry-clickhouse
              persistentVolumeClaim:
                claimName: sentry-clickhouse
            - name: sentry-clickhouse-log
              persistentVolumeClaim:
                claimName: sentry-clickhouse-log
      test: false
      triggers:
        - type: ConfigChange
    status: {}
  - apiVersion: v1
    kind: PersistentVolumeClaim
    metadata:
      creationTimestamp: null
      labels:
        io.sentry.service: sentry-clickhouse
      name: sentry-clickhouse
    spec:
      accessModes:
        - ReadWriteOnce
      resources:
        requests:
          storage: 4Gi
    status: {}
  - apiVersion: v1
    kind: PersistentVolumeClaim
    metadata:
      creationTimestamp: null
      labels:
        io.sentry.service: sentry-clickhouse-log
      name: sentry-clickhouse-log
    spec:
      accessModes:
        - ReadWriteOnce
      resources:
        requests:
          storage: 100Mi
    status: {}
  - apiVersion: v1
    kind: DeploymentConfig
    metadata:
      annotations:
      creationTimestamp: null
      labels:
        io.sentry.service: kafka
      name: kafka
    spec:
      replicas: 1
      selector:
        io.sentry.service: kafka
      strategy:
        resources: {}
        type: Recreate
      template:
        metadata:
          creationTimestamp: null
          labels:
            io.sentry.service: kafka
        spec:
          initContainers:
            - name: init-zookeeper
              image: "busybox:1.28.4"
              command: ["sh", "-c", "until nslookup zookeeper; do echo waiting for redis; sleep 2; done;"]
          containers:
            - env:
                - name: CONFLUENT_SUPPORT_METRICS_ENABLE
                  value: "false"
                - name: KAFKA_ADVERTISED_LISTENERS
                  value: PLAINTEXT://kafka-service:9092
                - name: KAFKA_LOG4J_LOGGERS
                  value: kafka.cluster=WARN,kafka.controller=WARN,kafka.coordinator=WARN,kafka.log=WARN,kafka.server=WARN,kafka.zookeeper=WARN,state.change.logger=WARN
                - name: KAFKA_LOG4J_ROOT_LOGLEVEL
                  value: WARN
                - name: KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR
                  value: "1"
                - name: KAFKA_MESSAGE_MAX_BYTES
                  value: '50000000' #50MB or bust
                - name: KAFKA_MAX_REQUEST_SIZE
                  value: '50000000' #50MB on requests apparently too
                - name: KAFKA_TOOLS_LOG4J_LOGLEVEL
                  value: WARN
                - name: KAFKA_ZOOKEEPER_CONNECT
                  value: zookeeper:2181
              image: "confluentinc/cp-kafka:5.5.0"
              name: kafka
              ports:
                - containerPort: 9092
              resources: {}
              volumeMounts:
                - mountPath: /var/lib/kafka/data
                  name: sentry-kafka
                  subPath: kafka-data
                - mountPath: /var/lib/kafka/log
                  name: sentry-kafka-log
                  subPath: kafka-logs
                - mountPath: /etc/kafka/secrets
                  name: sentry-secrets
          restartPolicy: Always
          serviceAccountName: "${SERVICE_ACCOUNT_NAME}"
          volumes:
            - name: sentry-kafka
              persistentVolumeClaim:
                claimName: sentry-kafka
            - name: sentry-kafka-log
              persistentVolumeClaim:
                claimName: sentry-kafka-log
            - name: sentry-secrets
              persistentVolumeClaim:
                claimName: sentry-secrets
      test: false
      triggers:
        - type: ConfigChange
    status: {}
  - apiVersion: batch/v1
    kind: Job
    metadata:
      annotations:
        template.alpha.openshift.io/wait-for-ready: "true"
      name: sentry-kafka-init-ingest-topics
      labels:
        component: sentry
    spec:
      selector: {}
      template:
        metadata:
          name: sentry-kafka-init-ingest-topics
          labels:
            component: sentry
        spec:
          initContainers:
            - name: init-kafka
              image: "busybox:1.28.4"
              command: ["sh", "-c", "until nslookup kafka-service; do echo waiting for kafka-service; sleep 2; done;"]
            - name: init-zookeeper
              image: "busybox:1.28.4"
              command: ["sh", "-c", "until nslookup zookeeper; do echo waiting for redis; sleep 2; done;"]
          containers:
            - name: kafka-init-ingest-topics
              env:
                - name: CONFLUENT_SUPPORT_METRICS_ENABLE
                  value: "false"
                - name: KAFKA_ADVERTISED_LISTENERS
                  value: PLAINTEXT://kafka-service:9092
                - name: KAFKA_LOG4J_LOGGERS
                  value: kafka.cluster=WARN,kafka.controller=WARN,kafka.coordinator=WARN,kafka.log=WARN,kafka.server=WARN,kafka.zookeeper=WARN,state.change.logger=WARN
                - name: KAFKA_LOG4J_ROOT_LOGLEVEL
                  value: WARN
                - name: KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR
                  value: "1"
                - name: KAFKA_MESSAGE_MAX_BYTES
                  value: '50000000' #50MB or bust
                - name: KAFKA_MAX_REQUEST_SIZE
                  value: '50000000' #50MB on requests apparently too
                - name: KAFKA_TOOLS_LOG4J_LOGLEVEL
                  value: WARN
                - name: KAFKA_ZOOKEEPER_CONNECT
                  value: zookeeper:2181
              image: "confluentinc/cp-kafka:5.5.0"
              resources: {}
              volumeMounts:
                - mountPath: /var/lib/kafka/data
                  name: sentry-kafka
                  subPath: kafka-data
                - mountPath: /var/lib/kafka/log
                  name: sentry-kafka-log
                  subPath: kafka-logs
                - mountPath: /etc/kafka/secrets
                  name: sentry-secrets
              command: 
                - sh
                - "-c"
                - |
                  kafka-topics --create --topic ingest-transactions --zookeeper ${KAFKA_ZOOKEEPER_CONNECT} --partitions 1 --replication-factor 1 \
                  && \
                  kafka-topics --create --topic ingest-events --zookeeper ${KAFKA_ZOOKEEPER_CONNECT} --partitions 1 --replication-factor 1 \
                  && \
                  kafka-topics --create --topic ingest-attachments --zookeeper ${KAFKA_ZOOKEEPER_CONNECT} --partitions 1 --replication-factor 1
          restartPolicy: OnFailure
          volumes:
            - name: sentry-kafka
              persistentVolumeClaim:
                claimName: sentry-kafka
            - name: sentry-kafka-log
              persistentVolumeClaim:
                claimName: sentry-kafka-log
            - name: sentry-secrets
              persistentVolumeClaim:
                claimName: sentry-secrets
  - apiVersion: v1
    kind: PersistentVolumeClaim
    metadata:
      creationTimestamp: null
      labels:
        io.sentry.service: sentry-kafka
      name: sentry-kafka
    spec:
      accessModes:
        - ReadWriteOnce
      resources:
        requests:
          storage: 16Gi
    status: {}
  - apiVersion: v1
    kind: PersistentVolumeClaim
    metadata:
      creationTimestamp: null
      labels:
        io.sentry.service: sentry-kafka-log
      name: sentry-kafka-log
    spec:
      accessModes:
        - ReadWriteOnce
      resources:
        requests:
          storage: 100Mi
    status: {}
  - apiVersion: v1
    kind: DeploymentConfig
    metadata:
      annotations:
      creationTimestamp: null
      labels:
        io.sentry.service: memcached
      name: memcached
    spec:
      replicas: 1
      selector:
        io.sentry.service: memcached
      strategy:
        resources: {}
      template:
        metadata:
          creationTimestamp: null
          labels:
            io.sentry.service: memcached
        spec:
          containers:
            - image: "memcached:1.5-alpine"
              name: memcached
              ports:
                - containerPort: 11211
              resources: {}
          restartPolicy: Always
      test: false
      triggers:
        - type: ConfigChange
    status: {}
  - apiVersion: v1
    kind: DeploymentConfig
    metadata:
      annotations:
      creationTimestamp: null
      labels:
        io.sentry.service: postgres
      name: postgres
    spec:
      replicas: 1
      selector:
        io.sentry.service: postgres
      strategy:
        resources: {}
        type: Recreate
      template:
        metadata:
          creationTimestamp: null
          labels:
            io.sentry.service: postgres
        spec:
          containers:
            - image: "postgres:9.6"
              name: postgres
              env:
              - name: POSTGRES_HOST_AUTH_METHOD
                value: "trust"
              ports:
                - containerPort: 5432
              resources: {}
              volumeMounts:
                - mountPath: /var/lib/postgresql/data
                  name: sentry-postgres
                  subPath: pgdata
          restartPolicy: Always
          serviceAccountName: "${SERVICE_ACCOUNT_NAME}"
          volumes:
            - name: sentry-postgres
              persistentVolumeClaim:
                claimName: sentry-postgres
      test: false
      triggers:
        - type: ConfigChange
    status: {}
  - apiVersion: v1
    kind: PersistentVolumeClaim
    metadata:
      creationTimestamp: null
      labels:
        io.sentry.service: sentry-postgres
      name: sentry-postgres
    spec:
      accessModes:
        - ReadWriteOnce
      resources:
        requests:
          storage: 60Gi
    status: {}
  - apiVersion: v1
    kind: DeploymentConfig
    metadata:
      annotations:
      creationTimestamp: null
      labels:
        io.sentry.service: redis
      name: redis
    spec:
      replicas: 1
      selector:
        io.sentry.service: redis
      strategy:
        resources: {}
        type: Recreate
      template:
        metadata:
          creationTimestamp: null
          labels:
            io.sentry.service: redis
        spec:
          containers:
            - image: "redis:5.0-alpine"
              name: redis
              ports:
                - containerPort: 6379
              resources: {}
              volumeMounts:
                - mountPath: /data
                  name: sentry-redis
          serviceAccountName: "${SERVICE_ACCOUNT_NAME}"
          restartPolicy: Always
          volumes:
            - name: sentry-redis
              persistentVolumeClaim:
                claimName: sentry-redis
      test: false
      triggers:
        - type: ConfigChange
    status: {}
  - apiVersion: v1
    kind: PersistentVolumeClaim
    metadata:
      creationTimestamp: null
      labels:
        io.sentry.service: sentry-redis
      name: sentry-redis
    spec:
      accessModes:
        - ReadWriteOnce
      resources:
        requests:
          storage: 100Mi
    status: {}
  - apiVersion: v1
    kind: DeploymentConfig
    metadata:
      annotations:
      creationTimestamp: null
      labels:
        io.sentry.service: smtp
      name: smtp
    spec:
      replicas: 1
      selector:
        io.sentry.service: smtp
      strategy:
        resources: {}
        type: Recreate
      template:
        metadata:
          creationTimestamp: null
          labels:
            io.sentry.service: smtp
        spec:
          containers:
            - image: "tianon/exim4"
              name: smtp
              ports:
                - containerPort: 25
              resources: {}
              volumeMounts:
                - mountPath: /var/spool/exim4
                  name: sentry-smtp
                - mountPath: /var/log/exim4
                  name: sentry-smtp-log
          serviceAccountName: "${SERVICE_ACCOUNT_NAME}"
          restartPolicy: Always
          volumes:
            - name: sentry-smtp
              persistentVolumeClaim:
                claimName: sentry-smtp
            - name: sentry-smtp-log
              persistentVolumeClaim:
                claimName: sentry-smtp-log
      test: false
      triggers:
        - type: ConfigChange
    status: {}
  - apiVersion: v1
    kind: PersistentVolumeClaim
    metadata:
      creationTimestamp: null
      labels:
        io.sentry.service: sentry-smtp
      name: sentry-smtp
    spec:
      accessModes:
        - ReadWriteOnce
      resources:
        requests:
          storage: 100Mi
    status: {}
  - apiVersion: v1
    kind: PersistentVolumeClaim
    metadata:
      creationTimestamp: null
      labels:
        io.sentry.service: sentry-smtp-log
      name: sentry-smtp-log
    spec:
      accessModes:
        - ReadWriteOnce
      resources:
        requests:
          storage: 100Mi
    status: {}
  - apiVersion: v1
    kind: DeploymentConfig
    metadata:
      annotations:
      creationTimestamp: null
      labels:
        io.sentry.service: snuba-api
      name: snuba-api
    spec:
      replicas: 1
      selector:
        io.sentry.service: snuba-api
      strategy:
        resources: {}
      template:
        metadata:
          creationTimestamp: null
          labels:
            io.sentry.service: snuba-api
        spec:
          initContainers:
            - name: init-redis
              image: "busybox:1.28.4"
              command: ["sh", "-c", "until nslookup redis; do echo waiting for redis; sleep 2; done;"]
            - name: init-clickhouse
              image: "busybox:1.28.4"
              command: ["sh", "-c", "until nslookup clickhouse; do echo waiting for clickhouse; sleep 2; done;"]
            - name: init-kafka
              image: "busybox:1.28.4"
              command: ["sh", "-c", "until nslookup kafka-service; do echo waiting for kafka-service; sleep 2; done;"]
            - name: init-snuba-bootstrapping
              envFrom:
                - configMapRef:
                    name: "sentry-snuba-config"
              image: "getsentry/snuba:latest"
              args:
                - snuba
                - bootstrap
                - --no-migrate
                - --force
            - name: init-snuba-migration
              envFrom:
                - configMapRef:
                    name: "sentry-snuba-config"
              image: "getsentry/snuba:latest"
              args:
                - snuba
                - migrations
                - migrate
                - --force
          containers:
            - envFrom:
                - configMapRef:
                    name: "sentry-snuba-config"
              image: "getsentry/snuba:latest"
              name: snuba-api
              ports:
                - containerPort: 1218
              resources: {}
          serviceAccountName: "${SERVICE_ACCOUNT_NAME}"
          restartPolicy: Always
      test: false
      triggers:
        - type: ConfigChange
    status: {}
  - apiVersion: v1
    kind: DeploymentConfig
    metadata:
      annotations:
      creationTimestamp: null
      labels:
        io.sentry.service: snuba-consumer
      name: snuba-consumer
    spec:
      replicas: 1
      selector:
        io.sentry.service: snuba-consumer
      strategy:
        resources: {}
      template:
        metadata:
          creationTimestamp: null
          labels:
            io.sentry.service: snuba-consumer
        spec:
          initContainers:
            - name: init-redis
              image: "busybox:1.28.4"
              command: ["sh", "-c", "until nslookup redis; do echo waiting for redis; sleep 2; done;"]
            - name: init-clickhouse
              image: "busybox:1.28.4"
              command: ["sh", "-c", "until nslookup clickhouse; do echo waiting for clickhouse; sleep 2; done;"]
            - name: init-kafka
              image: "busybox:1.28.4"
              command: ["sh", "-c", "until nslookup kafka-service; do echo waiting for kafka-service; sleep 2; done;"]
            - name: init-snuba-api
              image: "busybox:1.28.4"
              command: ["sh", "-c", "until nslookup snuba-api; do echo waiting for snuba-api; sleep 2; done;"]
          containers:
            - args:
                - consumer
                - --storage
                - events
                - --auto-offset-reset=latest
                - --max-batch-time-ms
                - "750"
              envFrom:
                - configMapRef:
                    name: "sentry-snuba-config"
              image: "getsentry/snuba:latest"
              name: snuba-consumer
              ports:
                - containerPort: 1218
              resources: {}
          restartPolicy: Always
          serviceAccountName: "${SERVICE_ACCOUNT_NAME}"
      test: false
      triggers:
        - type: ConfigChange
    status: {}
  - apiVersion: v1
    kind: DeploymentConfig
    metadata:
      annotations:
      creationTimestamp: null
      labels:
        io.sentry.service: snuba-outcomes-consumer
      name: snuba-outcomes-consumer
    spec:
      replicas: 1
      selector:
        io.sentry.service: snuba-outcomes-consumer
      strategy:
        resources: {}
      template:
        metadata:
          creationTimestamp: null
          labels:
            io.sentry.service: snuba-outcomes-consumer
        spec:
          initContainers:
            - name: init-redis
              image: "busybox:1.28.4"
              command: ["sh", "-c", "until nslookup redis; do echo waiting for redis; sleep 2; done;"]
            - name: init-clickhouse
              image: "busybox:1.28.4"
              command: ["sh", "-c", "until nslookup clickhouse; do echo waiting for clickhouse; sleep 2; done;"]
            - name: init-kafka
              image: "busybox:1.28.4"
              command: ["sh", "-c", "until nslookup kafka-service; do echo waiting for kafka-service; sleep 2; done;"]
            - name: init-snuba-api
              image: "busybox:1.28.4"
              command: ["sh", "-c", "until nslookup snuba-api; do echo waiting for snuba-api; sleep 2; done;"]
          containers:
            - args:
                - consumer
                - --storage
                - outcomes_raw
                - --auto-offset-reset=earliest
                - --max-batch-time-ms
                - "750"
              envFrom:
                - configMapRef:
                    name: "sentry-snuba-config"
              image: "getsentry/snuba:latest"
              name: snuba-outcomes-consumer
              ports:
                - containerPort: 1218
              resources: {}
          restartPolicy: Always
          serviceAccountName: "${SERVICE_ACCOUNT_NAME}"
      test: false
      triggers:
        - type: ConfigChange
    status: {}
  - apiVersion: v1
    kind: DeploymentConfig
    metadata:
      annotations:
      creationTimestamp: null
      labels:
        io.sentry.service: snuba-sessions-consumer
      name: snuba-sessions-consumer
    spec:
      replicas: 1
      selector:
        io.sentry.service: snuba-sessions-consumer
      strategy:
        resources: {}
      template:
        metadata:
          creationTimestamp: null
          labels:
            io.sentry.service: snuba-sessions-consumer
        spec:
          initContainers:
            - name: init-redis
              image: "busybox:1.28.4"
              command: ["sh", "-c", "until nslookup redis; do echo waiting for redis; sleep 2; done;"]
            - name: init-clickhouse
              image: "busybox:1.28.4"
              command: ["sh", "-c", "until nslookup clickhouse; do echo waiting for clickhouse; sleep 2; done;"]
            - name: init-kafka
              image: "busybox:1.28.4"
              command: ["sh", "-c", "until nslookup kafka-service; do echo waiting for kafka-service; sleep 2; done;"]
            - name: init-snuba-api
              image: "busybox:1.28.4"
              command: ["sh", "-c", "until nslookup snuba-api; do echo waiting for snuba-api; sleep 2; done;"]
          containers:
            - args:
                - consumer
                - --storage
                - sessions_raw
                - --auto-offset-reset=latest
                - --max-batch-time-ms
                - "750"
              envFrom:
                - configMapRef:
                    name: "sentry-snuba-config"
              image: "getsentry/snuba:latest"
              name: snuba-sessions-consumer
              ports:
                - containerPort: 1218
              resources: {}
          restartPolicy: Always
          serviceAccountName: "${SERVICE_ACCOUNT_NAME}"
      test: false
      triggers:
        - type: ConfigChange
    status: {}
  - apiVersion: v1
    kind: DeploymentConfig
    metadata:
      annotations:
      creationTimestamp: null
      labels:
        io.sentry.service: snuba-transactions-consumer
      name: snuba-transactions-consumer
    spec:
      replicas: 1
      selector:
        io.sentry.service: snuba-transactions-consumer
      strategy:
        resources: {}
      template:
        metadata:
          creationTimestamp: null
          labels:
            io.sentry.service: snuba-transactions-consumer
        spec:
          initContainers:
            - name: init-redis
              image: "busybox:1.28.4"
              command: ["sh", "-c", "until nslookup redis; do echo waiting for redis; sleep 2; done;"]
            - name: init-clickhouse
              image: "busybox:1.28.4"
              command: ["sh", "-c", "until nslookup clickhouse; do echo waiting for clickhouse; sleep 2; done;"]
            - name: init-kafka
              image: "busybox:1.28.4"
              command: ["sh", "-c", "until nslookup kafka-service; do echo waiting for kafka-service; sleep 2; done;"]
            - name: init-snuba-api
              image: "busybox:1.28.4"
              command: ["sh", "-c", "until nslookup snuba-api; do echo waiting for snuba-api; sleep 2; done;"]
          containers:
            - args:
                - consumer
                - --storage
                - transactions
                - --consumer-group
                - transactions_group
                - --auto-offset-reset=latest
                - --max-batch-time-ms
                - "750"
              envFrom:
                - configMapRef:
                    name: "sentry-snuba-config"
              image: "getsentry/snuba:latest"
              name: snuba-transactions-consumer
              ports:
                - containerPort: 1218
              resources: {}
          restartPolicy: Always
          serviceAccountName: "${SERVICE_ACCOUNT_NAME}"
      test: false
      triggers:
        - type: ConfigChange
    status: {}
  - apiVersion: v1
    kind: DeploymentConfig
    metadata:
      annotations:
      creationTimestamp: null
      labels:
        io.sentry.service: snuba-replacer
      name: snuba-replacer
    spec:
      replicas: 1
      selector:
        io.sentry.service: snuba-replacer
      strategy:
        resources: {}
      template:
        metadata:
          creationTimestamp: null
          labels:
            io.sentry.service: snuba-replacer
        spec:
          initContainers:
            - name: init-redis
              image: "busybox:1.28.4"
              command: ["sh", "-c", "until nslookup redis; do echo waiting for redis; sleep 2; done;"]
            - name: init-clickhouse
              image: "busybox:1.28.4"
              command: ["sh", "-c", "until nslookup clickhouse; do echo waiting for clickhouse; sleep 2; done;"]
            - name: init-kafka
              image: "busybox:1.28.4"
              command: ["sh", "-c", "until nslookup kafka-service; do echo waiting for kafka-service; sleep 2; done;"]
            - name: init-snuba-api
              image: "busybox:1.28.4"
              command: ["sh", "-c", "until nslookup snuba-api; do echo waiting for snuba-api; sleep 2; done;"]
          containers:
            - args:
                - replacer
                - --storage
                - events
                - --auto-offset-reset=latest
                - --max-batch-size
                - "3"
              envFrom:
                - configMapRef:
                    name: "sentry-snuba-config"
              image: "getsentry/snuba:latest"
              name: snuba-replacer
              ports:
                - containerPort: 1218
              resources: {}
          restartPolicy: Always
          serviceAccountName: "${SERVICE_ACCOUNT_NAME}"
      test: false
      triggers:
        - type: ConfigChange
    status: {}
  - apiVersion: batch/v1beta1
    kind: CronJob
    metadata:
      name: snuba-cleanup
      labels:
        component: snuba
    spec:
      schedule: "*/5 * * * *"
      concurrencyPolicy: Allow
      suspend: false
      successfulJobsHistoryLimit: 3
      failedJobsHistoryLimit: 1
      jobTemplate:
        spec:
          template:
            metadata:
              labels:
                component: snuba
            spec:
              initContainers:
                - name: init-redis
                  image: "busybox:1.28.4"
                  command: ["sh", "-c", "until nslookup redis; do echo waiting for redis; sleep 2; done;"]
                - name: init-clickhouse
                  image: "busybox:1.28.4"
                  command: ["sh", "-c", "until nslookup clickhouse; do echo waiting for clickhouse; sleep 2; done;"]
                - name: init-kafka
                  image: "busybox:1.28.4"
                  command: ["sh", "-c", "until nslookup kafka-service; do echo waiting for kafka-service; sleep 2; done;"]
              containers:
                - name: snuba-cleanup
                  image: "getsentry/snuba:latest"
                  command: ["sh", "-c", "snuba cleanup --dry-run False"]
                  envFrom:
                  - configMapRef:
                      name: "sentry-snuba-config"
              restartPolicy: Never
              serviceAccountName: "${SERVICE_ACCOUNT_NAME}"
  - apiVersion: v1
    kind: DeploymentConfig
    metadata:
      annotations:
      creationTimestamp: null
      labels:
        io.sentry.service: symbolicator
      name: symbolicator
    spec:
      replicas: 1
      selector:
        io.sentry.service: symbolicator
      strategy:
        resources: {}
        type: Recreate
      template:
        metadata:
          creationTimestamp: null
          labels:
            io.sentry.service: symbolicator
        spec:
          initContainers:
            - name: init-symbolicator-config
              image: "busybox:1.28.4"
              command: ["sh", "-c", "until [ -f /etc/symbolicator/config.yml ]; do echo waiting for config; sleep 2; done;"]
              volumeMounts:
                - mountPath: /etc/symbolicator
                  name: sentry-symbolicator-conf
          containers:
            - args:
                - run
                - -c 
                - /etc/symbolicator/config.yml
              image: "getsentry/symbolicator:latest"
              name: symbolicator
              ports:
                - containerPort: 3021
              resources: {}
              volumeMounts:
                - mountPath: /data
                  name: sentry-symbolicator
                - mountPath: /etc/symbolicator
                  name: sentry-symbolicator-conf
          restartPolicy: Always
          volumes:
            - name: sentry-symbolicator
              persistentVolumeClaim:
                claimName: sentry-symbolicator
            - name: sentry-symbolicator-conf
              persistentVolumeClaim:
                claimName: sentry-symbolicator-conf
      test: false
      triggers:
        - type: ConfigChange
    status: {}
  - apiVersion: v1
    kind: PersistentVolumeClaim
    metadata:
      creationTimestamp: null
      labels:
        io.sentry.service: sentry-symbolicator
      name: sentry-symbolicator
    spec:
      accessModes:
        - ReadWriteOnce
      resources:
        requests:
          storage: 100Mi
    status: {}
  - apiVersion: batch/v1beta1
    kind: CronJob
    metadata:
      name: symbolicator-cleanup
      labels:
        component: symbolicator
    spec:
      schedule: "55 23 * * *"
      concurrencyPolicy: Allow
      suspend: false
      successfulJobsHistoryLimit: 3
      failedJobsHistoryLimit: 1
      jobTemplate:
        spec:
          template:
            metadata:
              labels:
                component: symbolicator
            spec:
              containers:
                - name: symbolicator-cleanup
                  image: "getsentry/symbolicator:latest"
                  command: ["sh", "-c", "symbolicator cleanup"]
                  volumeMounts:
                    - mountPath: /data
                      name: sentry-symbolicator
              restartPolicy: OnFailure
              volumes:
                - name: sentry-symbolicator
                  persistentVolumeClaim:
                    claimName: sentry-symbolicator
  - apiVersion: batch/v1
    kind: Job
    metadata:
      annotations:
        template.alpha.openshift.io/wait-for-ready: "true"
      name: sentry-get-symbolicator-config
      labels:
        component: sentry
    spec:
      selector: {}
      template:
        metadata:
          name: sentry-get-symbolicator-config
          labels:
            component: sentry
        spec:
          containers:
            - name: sentry-get-symbolicator-config
              image: "curlimages/curl:latest"
              args:
                - -L 
                - https://raw.githubusercontent.com/SimonGolms/sentry-onpremise-openshift/master/openshift/symbolicator/config.yml 
                - -o 
                - /etc/symbolicator/config.yml
              volumeMounts:
                - mountPath: /etc/symbolicator
                  name: sentry-symbolicator-conf
              env:
                - name: http_proxy
                  value: "${HTTP_PROXY}"
                - name: https_proxy
                  value: "${HTTPS_PROXY}"
                - name: no_proxy
                  value: "${NO_PROXY}"
              securityContext:
                privileged: true
          restartPolicy: OnFailure
          volumes:
            - name: sentry-symbolicator-conf
              persistentVolumeClaim:
                claimName: sentry-symbolicator-conf
  - apiVersion: v1
    kind: PersistentVolumeClaim
    metadata:
      creationTimestamp: null
      labels:
        io.sentry.service: sentry-symbolicator-conf
      name: sentry-symbolicator-conf
    spec:
      accessModes:
        - ReadWriteOnce
      resources:
        requests:
          storage: 100Mi
    status: {}
  - apiVersion: v1
    kind: DeploymentConfig
    metadata:
      annotations:
      creationTimestamp: null
      labels:
        io.sentry.service: zookeeper
      name: zookeeper
    spec:
      replicas: 1
      selector:
        io.sentry.service: zookeeper
      strategy:
        resources: {}
        type: Recreate
      template:
        metadata:
          creationTimestamp: null
          labels:
            io.sentry.service: zookeeper
        spec:
          containers:
            - env:
                - name: CONFLUENT_SUPPORT_METRICS_ENABLE
                  value: "false"
                - name: ZOOKEEPER_CLIENT_PORT
                  value: "2181"
                - name: ZOOKEEPER_LOG4J_ROOT_LOGLEVEL
                  value: WARN
                - name: ZOOKEEPER_TOOLS_LOG4J_LOGLEVEL
                  value: WARN
              image: "confluentinc/cp-zookeeper:5.5.0"
              name: zookeeper
              ports:
                - containerPort: 2181
                - containerPort: 2888
                - containerPort: 3888
              resources: {}
              volumeMounts:
                - mountPath: /var/lib/zookeeper/data
                  name: sentry-zookeeper
                - mountPath: /var/lib/zookeeper/log
                  name: sentry-zookeeper-log
                - mountPath: /etc/zookeeper/secrets
                  name: sentry-secrets
          restartPolicy: Always
          volumes:
            - name: sentry-zookeeper
              persistentVolumeClaim:
                claimName: sentry-zookeeper
            - name: sentry-zookeeper-log
              persistentVolumeClaim:
                claimName: sentry-zookeeper-log
            - name: sentry-secrets
              persistentVolumeClaim:
                claimName: sentry-secrets
      test: false
      triggers:
        - type: ConfigChange
    status: {}
  - apiVersion: v1
    kind: PersistentVolumeClaim
    metadata:
      creationTimestamp: null
      labels:
        io.sentry.service: sentry-zookeeper
      name: sentry-zookeeper
    spec:
      accessModes:
        - ReadWriteOnce
      resources:
        requests:
          storage: 5Gi
    status: {}
  - apiVersion: v1
    kind: PersistentVolumeClaim
    metadata:
      creationTimestamp: null
      labels:
        io.sentry.service: sentry-zookeeper-log
      name: sentry-zookeeper-log
    spec:
      accessModes:
        - ReadWriteOnce
      resources:
        requests:
          storage: 100Mi
    status: {}
  - apiVersion: route.openshift.io/v1
    kind: Route
    metadata:
      name: sentry
    spec:
      host: "${SENTRY_HOST}"
      port:
        targetPort: "80"
      tls:
        insecureEdgeTerminationPolicy: Redirect
        termination: edge
      to:
        kind: Service
        name: nginx
        weight: 100
      wildcardPolicy: None
message: >-
  Once the 'web' and 'nginx' container is successfully started, sentry is available under the following url:

  ${SENTRY_HOST}


  Log in with the admin account to complete the configuration and continue setting up sentry.

  Account: ${ADMIN_USERNAME}

  Password: ${ADMIN_PASSWORD}
